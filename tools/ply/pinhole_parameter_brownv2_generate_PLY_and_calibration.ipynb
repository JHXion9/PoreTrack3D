{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件用于尝试通过图片和mask 生成 点云 和 标定数据。brownv1的前提下，更换这两个数据集即可 获得brownv2数据集\n",
    "\n",
    "该版本增加了参数方式，可以通过修改参数使得调用matlab生成不一样的东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #该文件的目标是，单纯的修改人物编号就可以生成点云，然后利用点云生成对应的patch\n",
    "#  即全部的文件结构都如下面所示，只需遍历人物编号即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "human_number ='043'\n",
    "dataset_path_call_matlab = '/media/human_face_need_test/brown_v2'\n",
    "\n",
    "\n",
    "# 修改文件夹使得文件夹结构存在project \n",
    "# 复制好图片和mask到project中\n",
    "human_full_path  =  os.path.join('/media/human_face_need_test/brown_v2',str(human_number),'EMO-1-shout+laugh','10')\n",
    "project_path = os.path.join(human_full_path,\"psiftproject\")\n",
    "project_images_path= os.path.join(project_path,\"images\")\n",
    "project_mask_path= os.path.join(project_path,\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/13.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/13.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/12.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/12.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/1.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/1.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/2.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/2.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/7.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/7.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/3.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/3.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/6.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/6.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/16.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/16.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/14.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/14.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/15.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/15.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/8.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/8.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/10.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/10.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/5.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/5.bmp\n",
      "Copied: /media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10/4.bmp -> /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/4.bmp\n",
      "Deleted: /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/mask/front_mask.bmp\n",
      "File does not exist: /media/human_face_need_test/brown_v2/099/EMO-1-shout+laugh/10/psiftproject/images/front.bmp\n"
     ]
    }
   ],
   "source": [
    "# 传入参数 执行psift 提取\n",
    "# 调用该matlab文件来生成psift\n",
    "\n",
    "\n",
    "# 输入文件的 组成结构:\n",
    "#  -data_path(可以是任意路径，下面的路径按着相同的结构来就行，只有人物编号可以修改)\n",
    "#  ++人物编号===\n",
    "#  +++EMO-1-shout+laugh\n",
    "#+ ++++10\n",
    "#  +++++psiftproject\n",
    "#  ++++++images\n",
    "#  ++++++mask\n",
    "#  ++++++descriptors\n",
    "#  ++++++keypoints\n",
    "\n",
    "\n",
    "\n",
    "# 该block 是将以前brown v1保存下来的数据集 修改成用于生成brown v2的格式 \n",
    "import os\n",
    "import shutil\n",
    "human_number ='099'\n",
    "\n",
    "\n",
    "\n",
    "# 修改文件夹使得文件夹结构存在project \n",
    "# 复制好图片和mask到project中\n",
    "human_full_path  =  os.path.join('/media/human_face_need_test/brown_v2',str(human_number),'EMO-1-shout+laugh','10')\n",
    "project_path = os.path.join(human_full_path,\"psiftproject\")\n",
    "project_images_path= os.path.join(project_path,\"images\")\n",
    "project_mask_path= os.path.join(project_path,\"mask\")\n",
    "if not os.path.exists(project_path):  # 如果不存在该文件夹\n",
    "    os.makedirs(project_path)  # 创建文件夹\n",
    "if not os.path.exists(project_images_path):  # 如果不存在该文件夹\n",
    "    os.makedirs(project_images_path) \n",
    "# 源路径和目标路径\n",
    "source_path = \"/media/human_face_need_test/brown_v2/018/EMO-1-shout+laugh/10\"\n",
    "target_path = project_images_path  # 假设 project_path 已经定义\n",
    "# 确保目标路径存在\n",
    "if not os.path.exists(target_path):\n",
    "    os.makedirs(target_path)\n",
    "\n",
    "# 遍历源路径下的所有文件\n",
    "for filename in os.listdir(source_path):\n",
    "    # 检查文件是否以 .bmp 结尾\n",
    "    if filename.endswith(\".bmp\"):\n",
    "        # 构建完整的源文件路径和目标文件路径\n",
    "        source_file = os.path.join(source_path, filename)\n",
    "        target_file = os.path.join(target_path, filename)\n",
    "        \n",
    "        # 复制文件（保留元数据）\n",
    "        shutil.copy2(source_file, target_file)\n",
    "        print(f\"Copied: {source_file} -> {target_file}\")\n",
    "\n",
    "shutil.copytree(os.path.join(human_full_path,'mask'), project_mask_path)\n",
    "\n",
    "#删除多余的正脸图片，这个只需要在生成图像块的时候使用\n",
    "project_front_mask_path= os.path.join(project_mask_path,\"front_mask.bmp\")\n",
    "project_front_images_path= os.path.join(project_images_path,\"front.bmp\")\n",
    "if os.path.exists(project_front_mask_path):\n",
    "    os.remove(project_front_mask_path)\n",
    "    print(f\"Deleted: {project_front_mask_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {project_front_mask_path}\")\n",
    "if os.path.exists(project_front_images_path):\n",
    "    os.remove(project_front_images_path)\n",
    "    print(f\"Deleted: {project_front_images_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {project_front_images_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入参数 执行psift 提取\n",
    "# 调用该matlab文件来生成psift\n",
    "\n",
    "# 输入参数为： 人物编号  所需kpts\n",
    "import subprocess\n",
    "import os\n",
    "get_sift_m='/media/dataset_maker_matlab_python/get_sift/parameter_eth_get_face_sift.m'\n",
    "\n",
    "#人物编号\n",
    "# 定义参数\n",
    "dataset_path_call_matlab = '/media/human_face_need_test/brown_v2'\n",
    "get_sift_human_number =  human_number\n",
    "kpts_number = 8080\n",
    "\n",
    "# 将参数写入 txt 文件\n",
    "with open(\"get_sift_parameters.txt\", \"w\") as f:\n",
    "    f.write(f\"dataset_path_call_matlab={dataset_path_call_matlab}\\n\")\n",
    "    f.write(f\"human_number={get_sift_human_number}\\n\")\n",
    "    f.write(f\"kpts_number={kpts_number}\\n\")\n",
    "\n",
    "print(\"参数已写入 parameters.txt\")\n",
    "\n",
    "#调用matlab\n",
    "subprocess.run([\"/usr/local/Matlab/R2020a/bin//matlab\", \"-nodisplay\", \"-nosplash\", \"-r\", \"run('{}'); exit\".format(get_sift_m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2020 The MathWorks, Inc.\n",
      "                  R2020a (9.8.0.1323502) 64-bit (glnxa64)\n",
      "                             February 25, 2020\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "py_patch_size:  \n",
      "folder_path: /media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/images\n",
      "folder_path_pathkp: /media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/keypoints\n",
      "save_path: /media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/1.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/10.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/12.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/13.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/14.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/15.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/16.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/2.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/3.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/4.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/5.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/6.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/7.bmp.bin.patches.mat\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/8.bmp.bin.patches.mat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/usr/local/Matlab/R2020a/bin//matlab', '-nodisplay', '-nosplash', '-r', \"run('/media/dataset_maker_matlab_python/local-feature-evaluation-master/scripts/parameter_extract_patch.m'); exit\"], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#挖取patch并保存   \n",
    "import subprocess\n",
    "# 调用该文件 进行patch的挖取，此处挖取所得的patch大小为  (patch_size/2-1)*2+1 ,可以根据所需patch1大小进行修改patch_size的参数\n",
    "patch_size = 32\n",
    "patch_folder_path = os.path.join(dataset_path_call_matlab,human_number,'EMO-1-shout+laugh/10/psiftproject/images')\n",
    "patch_folder_path_pathkp = os.path.join(dataset_path_call_matlab,human_number,'EMO-1-shout+laugh/10/psiftproject/keypoints')\n",
    "patch_save_path = os.path.join(dataset_path_call_matlab,human_number,'EMO-1-shout+laugh/10/psiftproject/descriptors')\n",
    "# 确保patch_save_path路径存在\n",
    "if not os.path.exists(patch_save_path):\n",
    "    os.makedirs(patch_save_path)\n",
    "\n",
    "\n",
    "with open(\"get_patch_parameters.txt\", \"w\") as f:\n",
    "    f.write(f\"patch_size={patch_size}\\n\")\n",
    "    f.write(f\"patch_folder_path={patch_folder_path}\\n\")\n",
    "    f.write(f\"patch_folder_path_pathkp={patch_folder_path_pathkp}\\n\")\n",
    "    f.write(f\"patch_save_path={patch_save_path}\\n\")\n",
    "\n",
    "extract_patch_m='/media/dataset_maker_matlab_python/local-feature-evaluation-master/scripts/parameter_extract_patch.m'\n",
    "subprocess.run([\"/usr/local/Matlab/R2020a/bin//matlab\", \"-nodisplay\", \"-nosplash\", \"-r\", \"run('{}'); exit\".format(extract_patch_m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50266/2877345591.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(net_modelpath))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提取出描述子并保存\n",
    "#调用python   feature_extraction_hynet_input32.py\n",
    "# 加载hynet模型\n",
    "from brownv2_hymodel import HyNet\n",
    "import torch\n",
    "gpu_id=0\n",
    "device = torch.device(\"cuda:{}\".format(gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "net_modelpath = '/media/human_face_need_test/HyNet/Research/mydata/network/2024-11-14_12:03:05HyNet_human_patch_sz_32_pt_512_pat_2_dim_128_alpha_2_margin_1.2_drop_0.3_lr_0.01_Adam_None_aug/net-best.pth'\n",
    "model = HyNet().eval()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(net_modelpath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/13.bmp.bin.patches.mat\n",
      "Computing features for 13.bmp [1/14] in 0.560s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/12.bmp.bin.patches.mat\n",
      "Computing features for 12.bmp [2/14] in 0.289s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/1.bmp.bin.patches.mat\n",
      "Computing features for 1.bmp [3/14] in 0.284s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/2.bmp.bin.patches.mat\n",
      "Computing features for 2.bmp [4/14] in 0.263s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/7.bmp.bin.patches.mat\n",
      "Computing features for 7.bmp [5/14] in 0.249s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/3.bmp.bin.patches.mat\n",
      "Computing features for 3.bmp [6/14] in 0.266s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/6.bmp.bin.patches.mat\n",
      "Computing features for 6.bmp [7/14] in 0.262s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/16.bmp.bin.patches.mat\n",
      "Computing features for 16.bmp [8/14] in 0.244s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/14.bmp.bin.patches.mat\n",
      "Computing features for 14.bmp [9/14] in 0.243s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/15.bmp.bin.patches.mat\n",
      "Computing features for 15.bmp [10/14] in 0.267s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/8.bmp.bin.patches.mat\n",
      "Computing features for 8.bmp [11/14] in 0.277s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/10.bmp.bin.patches.mat\n",
      "Computing features for 10.bmp [12/14] in 0.255s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/5.bmp.bin.patches.mat\n",
      "Computing features for 5.bmp [13/14] in 0.229s\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject/descriptors/4.bmp.bin.patches.mat\n",
      "Computing features for 4.bmp [14/14] in 0.218s\n"
     ]
    }
   ],
   "source": [
    "# 此处是 31patch 大小的，等等修改成63 resize的\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "def write_matrix(path, matrix):\n",
    "    with open(path, \"wb\") as fid:\n",
    "        shape = np.array(matrix.shape, dtype=np.int32)\n",
    "        shape.tofile(fid)\n",
    "        matrix.tofile(fid)\n",
    "\n",
    "def read_mat_file(file_path):\n",
    "    # 读取 .mat 文件\n",
    "    mat_contents = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # 返回读取的内容\n",
    "    return mat_contents\n",
    "\n",
    "\n",
    "#读入patch数据\n",
    "batch_size = 512\n",
    "image_names = os.listdir(patch_folder_path)\n",
    "for i, image_name in enumerate(image_names):\n",
    "\n",
    "    patches_path = os.path.join(patch_save_path,\n",
    "                                image_name + \".bin.patches.mat\")\n",
    "    print(patches_path)\n",
    "    if not os.path.exists(patches_path):\n",
    "        continue\n",
    "\n",
    "    print(\"Computing features for {} [{}/{}]\".format(\n",
    "            image_name, i + 1, len(image_names)), end=\"\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    descriptors_path = os.path.join(patch_save_path,\n",
    "                                    image_name + \".bin\")\n",
    "    # if os.path.exists(descriptors_path):\n",
    "    #     print(\" -> skipping, already exist\")\n",
    "    #     continue\n",
    "    mat_data = read_mat_file(patches_path)\n",
    "    patches31 = np.array(mat_data[\"patch\"])\n",
    "\n",
    "    if patches31.ndim != 3:\n",
    "        print(\" -> skipping, invalid input\")\n",
    "        write_matrix(descriptors_path, np.zeros((0, 512), dtype=np.float32))\n",
    "        continue\n",
    "\n",
    "    patches = np.empty((patches31.shape[0], 32, 32), dtype=np.float32)\n",
    "    patches[:, :31, :31] = patches31\n",
    "    patches[:, 31, :31] = patches31[:, 30, :]\n",
    "    patches[:, :31, 31] = patches31[:, :, 30]\n",
    "    patches[:, 31, 31] = patches31[:, 30, 30]\n",
    "\n",
    "    descriptors = []\n",
    "    for i in range(0, patches.shape[0], batch_size):\n",
    "        patches_batch = \\\n",
    "            patches[i:min(i + batch_size, patches.shape[0])]\n",
    "        patches_batch = \\\n",
    "            torch.from_numpy(patches_batch[:, None]).float().to(device)\n",
    "        # descriptors.append(tfeat(patches_batch).detach().cpu().numpy())\n",
    "        descriptors.append(model(patches_batch).detach().cpu().numpy())\n",
    "\n",
    "    if len(descriptors) == 0:\n",
    "        descriptors = np.zeros((0, 128), dtype=np.float32)\n",
    "    else:\n",
    "        descriptors = np.concatenate(descriptors)\n",
    "\n",
    "    write_matrix(descriptors_path, descriptors)\n",
    "\n",
    "    print(\" in {:.3f}s\".format(time.time() - start_time))\n",
    "\n",
    "#生成描述子并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2020 The MathWorks, Inc.\n",
      "                  R2020a (9.8.0.1323502) 64-bit (glnxa64)\n",
      "                             February 25, 2020\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "DATASET_ROOT: /media/human_face_need_test/brown_v2\n",
      "    {'043'}\n",
      "\n",
      "/media/human_face_need_test/brown_v2/043/EMO-1-shout+laugh/10/psiftproject\n",
      "Matching block [1/1, 1/1]Warning: The CUDA driver must recompile the GPU libraries because your device\n",
      "is more recent than the libraries. Recompiling can take several minutes. \n",
      "> In exhaustive_matching (line 37)\n",
      "  In parameter_matching_pipeline (line 132)\n",
      "  In run (line 91) \n",
      " in 2.618s\n",
      "matches的总数是: 266300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/usr/local/Matlab/R2020a/bin//matlab', '-nodisplay', '-nosplash', '-r', \"run('/media/dataset_maker_matlab_python/local-feature-evaluation-master/scripts/parameter_matching_pipeline.m'); exit\"], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成matches\n",
    "import subprocess\n",
    "# 输入参数，用于生成matches\n",
    "# dataset_root 人物编号  前面的路径，可自定义\n",
    "# human_number 制作哪一个number\n",
    "dataset_root = dataset_path_call_matlab\n",
    "match_human_number = human_number\n",
    "with open(\"matching_parameters.txt\", \"w\") as f:\n",
    "    f.write(f\"dataset_root={dataset_root}\\n\")\n",
    "    f.write(f\"match_human_number={match_human_number}\\n\")\n",
    "#创建matching 文件夹\n",
    "match_m='/media/dataset_maker_matlab_python/local-feature-evaluation-master/scripts/parameter_matching_pipeline.m'\n",
    "subprocess.run([\"/usr/local/Matlab/R2020a/bin//matlab\", \"-nodisplay\", \"-nosplash\", \"-r\", \"run('{}'); exit\".format(match_m)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================\n",
      "Feature extraction\n",
      "==============================================================================\n",
      "\n",
      "Processed file [1/14]\n",
      "  Name:            13.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #4 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9507\n",
      "Processed file [2/14]\n",
      "  Name:            1.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #1 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9552\n",
      "Processed file [3/14]\n",
      "  Name:            10.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #2 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        11763\n",
      "Processed file [4/14]\n",
      "  Name:            14.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #5 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9438\n",
      "Processed file [5/14]\n",
      "  Name:            15.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #6 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        10539\n",
      "Processed file [6/14]\n",
      "  Name:            16.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #7 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        7422\n",
      "Processed file [7/14]\n",
      "  Name:            2.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #8 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9555\n",
      "Processed file [8/14]\n",
      "  Name:            12.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #3 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9923\n",
      "Processed file [9/14]\n",
      "  Name:            3.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #9 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9143\n",
      "Processed file [10/14]\n",
      "  Name:            4.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #10 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        8758\n",
      "Processed file [11/14]\n",
      "  Name:            5.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #11 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        11610\n",
      "Processed file [12/14]\n",
      "  Name:            7.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #13 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        8325\n",
      "Processed file [13/14]\n",
      "  Name:            8.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #14 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        8860\n",
      "Processed file [14/14]\n",
      "  Name:            6.bmp\n",
      "  Dimensions:      2200 x 3208\n",
      "  Camera:          #12 - PINHOLE\n",
      "  Focal Length:    3849.60px\n",
      "  Features:        9022\n",
      "Elapsed time: 0.021 [minutes]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成对应的db  ，其中 model_select是选择对应的相机模型，这里虽然是提取了特征描述子和keypoints，但并不适用这里的提取的kpt和描述子\n",
    "# 只是利用这个方法来生成所需的db文件格式与对应的相机模型，在后续的重建文件中，会将墙面psift关键点和 hynet描述子写入db中\n",
    "# colmap_bat_path colmap所在位置\n",
    "import subprocess\n",
    "colmap_project_for_store_colmap_data_path  = project_path\n",
    "db_maker_image_path=project_images_path\n",
    "colmap_bat_path  = '/media/amax/ef914467-feed-4743-b2ec-58c3abb24e7a/LHW/ETH/local-feature-evaluation/colmap/build/src/exe/colmap'\n",
    "cmd_feature_extractor = ' feature_extractor --database_path {} --image_path {} --ImageReader.camera_model {}'.format(colmap_project_for_store_colmap_data_path+'/database.db',db_maker_image_path,\"PINHOLE\")\n",
    "subprocess.call(colmap_bat_path+cmd_feature_extractor,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/DGST_data/Test_Data/056/EMO-1-shout+laugh/2/psiftproject\n",
      "Importing features for 1.png\n",
      "Importing features for 10.png\n",
      "Importing features for 11.png\n",
      "Importing features for 12.png\n",
      "Importing features for 13.png\n",
      "Importing features for 14.png\n",
      "Importing features for 15.png\n",
      "Importing features for 16.png\n",
      "Importing features for 2.png\n",
      "Importing features for 3.png\n",
      "Importing features for 4.png\n",
      "Importing features for 5.png\n",
      "Importing features for 6.png\n",
      "Importing features for 7.png\n",
      "Importing features for 8.png\n",
      "Importing features for 9.png\n",
      "Importing matches for 10.png --- 7.png\n",
      "Importing matches for 3.png --- 7.png\n",
      "Importing matches for 13.png --- 8.png\n",
      "Importing matches for 11.png --- 15.png\n",
      "Importing matches for 13.png --- 16.png\n",
      "Importing matches for 10.png --- 11.png\n",
      "Importing matches for 10.png --- 14.png\n",
      "Importing matches for 3.png --- 6.png\n",
      "Importing matches for 2.png --- 4.png\n",
      "Importing matches for 10.png --- 8.png\n",
      "Importing matches for 14.png --- 9.png\n",
      "Importing matches for 14.png --- 4.png\n",
      "Importing matches for 12.png --- 15.png\n",
      "Importing matches for 11.png --- 3.png\n",
      "Importing matches for 1.png --- 6.png\n",
      "Importing matches for 1.png --- 7.png\n",
      "Importing matches for 12.png --- 2.png\n",
      "Importing matches for 4.png --- 8.png\n",
      "Importing matches for 11.png --- 7.png\n",
      "Importing matches for 1.png --- 3.png\n",
      "Importing matches for 14.png --- 8.png\n",
      "Importing matches for 16.png --- 2.png\n",
      "Importing matches for 6.png --- 8.png\n",
      "Importing matches for 2.png --- 5.png\n",
      "Importing matches for 10.png --- 13.png\n",
      "Importing matches for 3.png --- 5.png\n",
      "Importing matches for 1.png --- 12.png\n",
      "Importing matches for 12.png --- 16.png\n",
      "Importing matches for 1.png --- 13.png\n",
      "Importing matches for 16.png --- 9.png\n",
      "Importing matches for 1.png --- 15.png\n",
      "Importing matches for 11.png --- 16.png\n",
      "Importing matches for 5.png --- 6.png\n",
      "Importing matches for 7.png --- 9.png\n",
      "Importing matches for 12.png --- 6.png\n",
      "Importing matches for 1.png --- 8.png\n",
      "Importing matches for 14.png --- 7.png\n",
      "Importing matches for 14.png --- 2.png\n",
      "Importing matches for 12.png --- 13.png\n",
      "Importing matches for 1.png --- 11.png\n",
      "Importing matches for 13.png --- 15.png\n",
      "Importing matches for 12.png --- 9.png\n",
      "Importing matches for 15.png --- 16.png\n",
      "Importing matches for 11.png --- 4.png\n",
      "Importing matches for 10.png --- 12.png\n",
      "Importing matches for 1.png --- 4.png\n",
      "Importing matches for 10.png --- 16.png\n",
      "Importing matches for 11.png --- 8.png\n",
      "Importing matches for 1.png --- 9.png\n",
      "Importing matches for 4.png --- 6.png\n",
      "Importing matches for 12.png --- 4.png\n",
      "Importing matches for 14.png --- 16.png\n",
      "Importing matches for 16.png --- 7.png\n",
      "Importing matches for 5.png --- 9.png\n",
      "Importing matches for 3.png --- 8.png\n",
      "Importing matches for 10.png --- 15.png\n",
      "Importing matches for 14.png --- 6.png\n",
      "Importing matches for 16.png --- 3.png\n",
      "Importing matches for 13.png --- 2.png\n",
      "Importing matches for 13.png --- 5.png\n",
      "Importing matches for 14.png --- 5.png\n",
      "Importing matches for 15.png --- 5.png\n",
      "Importing matches for 4.png --- 9.png\n",
      "Importing matches for 15.png --- 4.png\n",
      "Importing matches for 2.png --- 8.png\n",
      "Importing matches for 14.png --- 15.png\n",
      "Importing matches for 1.png --- 14.png\n",
      "Importing matches for 13.png --- 3.png\n",
      "Importing matches for 15.png --- 3.png\n",
      "Importing matches for 4.png --- 5.png\n",
      "Importing matches for 16.png --- 6.png\n",
      "Importing matches for 2.png --- 3.png\n",
      "Importing matches for 12.png --- 14.png\n",
      "Importing matches for 3.png --- 4.png\n",
      "Importing matches for 1.png --- 5.png\n",
      "Importing matches for 13.png --- 6.png\n",
      "Importing matches for 11.png --- 9.png\n",
      "Importing matches for 12.png --- 5.png\n",
      "Importing matches for 11.png --- 6.png\n",
      "Importing matches for 13.png --- 7.png\n",
      "Importing matches for 11.png --- 2.png\n",
      "Importing matches for 14.png --- 3.png\n",
      "Importing matches for 11.png --- 12.png\n",
      "Importing matches for 6.png --- 9.png\n",
      "Importing matches for 6.png --- 7.png\n",
      "Importing matches for 7.png --- 8.png\n",
      "Importing matches for 13.png --- 9.png\n",
      "Importing matches for 15.png --- 2.png\n",
      "Importing matches for 12.png --- 8.png\n",
      "Importing matches for 10.png --- 4.png\n",
      "Importing matches for 2.png --- 7.png\n",
      "Importing matches for 15.png --- 6.png\n",
      "Importing matches for 5.png --- 7.png\n",
      "Importing matches for 10.png --- 3.png\n",
      "Importing matches for 2.png --- 6.png\n",
      "Importing matches for 16.png --- 5.png\n",
      "Importing matches for 8.png --- 9.png\n",
      "Importing matches for 12.png --- 3.png\n",
      "Importing matches for 1.png --- 2.png\n",
      "Importing matches for 15.png --- 8.png\n",
      "Importing matches for 5.png --- 8.png\n",
      "Importing matches for 3.png --- 9.png\n",
      "Importing matches for 11.png --- 13.png\n",
      "Importing matches for 10.png --- 2.png\n",
      "Importing matches for 10.png --- 5.png\n",
      "Importing matches for 10.png --- 9.png\n",
      "Importing matches for 15.png --- 7.png\n",
      "Importing matches for 16.png --- 8.png\n",
      "Importing matches for 1.png --- 16.png\n",
      "Importing matches for 12.png --- 7.png\n",
      "Importing matches for 13.png --- 14.png\n",
      "Importing matches for 1.png --- 10.png\n",
      "Importing matches for 11.png --- 14.png\n",
      "Importing matches for 16.png --- 4.png\n",
      "Importing matches for 4.png --- 7.png\n",
      "Importing matches for 11.png --- 5.png\n",
      "Importing matches for 15.png --- 9.png\n",
      "Importing matches for 2.png --- 9.png\n",
      "Importing matches for 10.png --- 6.png\n",
      "Importing matches for 13.png --- 4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0213 14:01:55.174925 1469259 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature matching\n",
      "==============================================================================\n",
      "I0213 14:01:55.175254 1469260 sift.cc:1426] Creating SIFT GPU feature matcher\n",
      "I0213 14:01:55.175381 1469261 sift.cc:1426] Creating SIFT GPU feature matcher\n",
      "I0213 14:01:55.175460 1469262 sift.cc:1426] Creating SIFT GPU feature matcher\n",
      "I0213 14:01:55.175541 1469264 sift.cc:1426] Creating SIFT GPU feature matcher\n",
      "I0213 14:01:56.131484 1469259 pairing.cc:747] Importing image pairs...\n",
      "I0213 14:01:56.131785 1469259 pairing.cc:780] Matching block [1/1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1468585/3784911859.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruct_py\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'--dataset_path={reconstruct_dataset_path}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 使用 subprocess.run 执行脚本并传递参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/4DGS/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/4DGS/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/4DGS/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/4DGS/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/4DGS/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0213 14:02:02.900199 1469259 feature_matching.cc:46] in 6.768s\n",
      "I0213 14:02:02.912860 1469259 timer.cc:91] Elapsed time: 0.129 [minutes]\n"
     ]
    }
   ],
   "source": [
    "#跑后面的程序，生成ply和稀疏\n",
    "#复制colmap所需的db文件，这其实只需要有一个正确格式的db就ok，里面存储什么数据都无所谓，因为会删除，重新写入\n",
    "\n",
    "import shutil\n",
    "# reconstruct_dataset_path = project_path\n",
    "reconstruct_dataset_path = \"/media/DGST_data/Test_Data/056/EMO-1-shout+laugh/2/psiftproject\"\n",
    "# 跑 reconstruction\n",
    "import subprocess\n",
    "reconstruct_py = '/media/Trajectory3D/tools/ply/local-feature-evaluation-master/scripts/pinhole_parameter_reconstruction_pipeline.py'\n",
    "\n",
    "args = ['python', reconstruct_py, f'--dataset_path={reconstruct_dataset_path}']\n",
    "# 使用 subprocess.run 执行脚本并传递参数\n",
    "subprocess.run(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用生成好的文件进行brownv2生成"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4DGS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
